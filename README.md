## Domainspecific-pretrain-for-BERT

 A nagyméretű, transzformer alapú nyelvmodelleket sokmilliárd szavas gigakorpuszok segítségével lehet megtanítani egy nyelvre (vagy többre).
 Legyen bármekkora is az eredeti tanítóadat, nem lehet a modelleket minden specifikus esetre felkészteni. A sajátos szakmai nyelvezet, például az orvosi szóhasználatban, a rendőrségen, a különféle jogi szövegekben egyaránt megjelenik. Ha a nyelvmodellt ilyen feadatra szerenénk használni, akkor célszerú az alapmodell továbbtanítani az adott szaknyelv szófordulataira, mondatszerkesztési megoldásaira, szerkezeteire. Az alábbi megoldás ebben segít. Tanítsuk tovább az általános nyelvmodellt, hogy a különböző feladatokban jobban teljesítsen.
